---
title: "PaperReading: MLLM_4 - Multimodal In-Context Learning"
timestamp: 2026-01-31 00:00:00+08:00
series: PaperReading
tags: [MLLM, Paper, ICL]
description: 多模态上下文学习相关论文阅读。
---

### Description

> [!NOTE] 普通论文
> 标准论文记录,蓝色

> [!TIP] 推荐阅读
> 特别推荐的经典论文,绿色

> [!IMPORTANT] 重要突破
> 里程碑式的重要论文,紫色

> [!WARNING] 需注意
> 有争议或需要特别注意的论文,橙色

<br>

## Visual In-Context Learning for Large Vision-Language Models

> [!NOTE] Visual ICL
> **Arxiv** [2402.11574](https://arxiv.org/abs/2402.11574)
>
> **翻译** [2402.11574](https://hjfy.top/arxiv/2402.11574)

## RAG-Driver

> [!NOTE] RAG-Driver
> **Arxiv** [2402.10828](https://arxiv.org/abs/2402.10828)
>
> **翻译** [2402.10828](https://hjfy.top/arxiv/2402.10828)
>
> **代码** [Github](https://github.com/YuanJianhao508/RAG-Driver)

## CoBSAT

> [!NOTE] CoBSAT
> **Arxiv** [2402.01293](https://arxiv.org/abs/2402.01293)
>
> **翻译** [2402.01293](https://hjfy.top/arxiv/2402.01293)
>
> **代码** [Github](https://github.com/UW-Madison-Lee-Lab/CoBSAT)

## Emu2

> [!NOTE] Emu2
> **Arxiv** [2312.13286](https://arxiv.org/abs/2312.13286)
>
> **翻译** [2312.13286](https://hjfy.top/arxiv/2312.13286)
>
> **代码** [Github](https://github.com/baaivision/Emu/tree/main/Emu2)
>
> **Demo** [Demo](https://huggingface.co/spaces/BAAI/Emu2)

## Hijacking Context in Large Multi-modal Models

> [!NOTE] Hijacking
> **Arxiv** [2312.07553](https://arxiv.org/abs/2312.07553)
>
> **翻译** [2312.07553](https://hjfy.top/arxiv/2312.07553)

## Unified In-context Visual Understanding

> [!NOTE] Unified ICL
> **Arxiv** [2312.02520](https://arxiv.org/abs/2312.02520)
>
> **翻译** [2312.02520](https://hjfy.top/arxiv/2312.02520)

## MMICL

> [!NOTE] MMICL
> **Arxiv** [2309.07915](https://arxiv.org/abs/2309.07915)
>
> **翻译** [2309.07915](https://hjfy.top/arxiv/2309.07915)
>
> **代码** [Github](https://github.com/HaozheZhao/MIC)
>
> **Demo** [Demo](https://8904cdd23621858859.gradio.live/)

## Link-Context Learning

> [!NOTE] Link-Context
> **Arxiv** [2308.07891](https://arxiv.org/abs/2308.07891)
>
> **翻译** [2308.07891](https://hjfy.top/arxiv/2308.07891)
>
> **代码** [Github](https://github.com/isekai-portal/Link-Context-Learning)
>
> **Demo** [Demo](http://117.144.81.99:20488/)

## OpenFlamingo

> [!IMPORTANT] OpenFlamingo
> **Arxiv** [2308.01390](https://arxiv.org/abs/2308.01390)
>
> **翻译** [2308.01390](https://hjfy.top/arxiv/2308.01390)
>
> **代码** [Github](https://github.com/mlfoundations/open_flamingo)
>
> **Demo** [Demo](https://huggingface.co/spaces/openflamingo/OpenFlamingo)

## Med-Flamingo

> [!NOTE] Med-Flamingo
> **Arxiv** [2307.15189](https://arxiv.org/abs/2307.15189)
>
> **翻译** [2307.15189](https://hjfy.top/arxiv/2307.15189)
>
> **代码** [Github](https://github.com/snap-stanford/med-flamingo)

## Emu

> [!NOTE] Emu
> **Arxiv** [2307.05222](https://arxiv.org/abs/2307.05222)
>
> **翻译** [2307.05222](https://hjfy.top/arxiv/2307.05222)
>
> **代码** [Github](https://github.com/baaivision/Emu/tree/main/Emu1)
>
> **Demo** [Demo](http://218.91.113.230:9002/)

## AVIS

> [!NOTE] AVIS
> **Arxiv** [2306.08129](https://arxiv.org/abs/2306.08129)
>
> **翻译** [2306.08129](https://hjfy.top/arxiv/2306.08129)

## MIMIC-IT

> [!NOTE] MIMIC-IT
> **Arxiv** [2306.05425](https://arxiv.org/abs/2306.05425)
>
> **翻译** [2306.05425](https://hjfy.top/arxiv/2306.05425)
>
> **代码** [Github](https://github.com/Luodian/Otter)
>
> **Demo** [Demo](https://otter.cliangyu.com/)

## ExploreCfg

> [!NOTE] ExploreCfg
> **Arxiv** [2305.14800](https://arxiv.org/abs/2305.14800)
>
> **翻译** [2305.14800](https://hjfy.top/arxiv/2305.14800)
>
> **代码** [Github](https://github.com/yongliang-wu/ExploreCfg)

## Chameleon

> [!NOTE] Chameleon
> **Arxiv** [2304.09842](https://arxiv.org/abs/2304.09842)
>
> **翻译** [2304.09842](https://hjfy.top/arxiv/2304.09842)
>
> **代码** [Github](https://github.com/lupantech/chameleon-llm)
>
> **Demo** [Demo](https://chameleon-llm.github.io/)

## HuggingGPT

> [!IMPORTANT] HuggingGPT
> **Arxiv** [2303.17580](https://arxiv.org/abs/2303.17580)
>
> **翻译** [2303.17580](https://hjfy.top/arxiv/2303.17580)
>
> **代码** [Github](https://github.com/microsoft/JARVIS)
>
> **Demo** [Demo](https://huggingface.co/spaces/microsoft/HuggingGPT)

## MM-REACT

> [!NOTE] MM-REACT
> **Arxiv** [2303.11381](https://arxiv.org/abs/2303.11381)
>
> **翻译** [2303.11381](https://hjfy.top/arxiv/2303.11381)
>
> **代码** [Github](https://github.com/microsoft/MM-REACT)
>
> **Demo** [Demo](https://huggingface.co/spaces/microsoft-cognitive-service/mm-react)

## ICL-D3IE

> [!NOTE] ICL-D3IE
> **Arxiv** [2303.05063](https://arxiv.org/abs/2303.05063)
>
> **翻译** [2303.05063](https://hjfy.top/arxiv/2303.05063)
>
> **代码** [Github](https://github.com/MAEHCM/ICL-D3IE)

## Prophet

> [!NOTE] Prophet
> **Arxiv** [2303.01903](https://arxiv.org/abs/2303.01903)
>
> **翻译** [2303.01903](https://hjfy.top/arxiv/2303.01903)
>
> **代码** [Github](https://github.com/MILVLG/prophet)

## VisProg

> [!IMPORTANT] VisProg
> **Arxiv** [2211.11559](https://arxiv.org/abs/2211.11559)
>
> **翻译** [2211.11559](https://hjfy.top/arxiv/2211.11559)
>
> **代码** [Github](https://github.com/allenai/visprog)

## PICa

> [!NOTE] PICa
> **Arxiv** [2206.01242](https://arxiv.org/abs/2206.01242)
>
> **翻译** [2206.01242](https://hjfy.top/arxiv/2206.01242)
>
> **代码** [Github](https://github.com/microsoft/PICa)

## Flamingo

> [!IMPORTANT] Flamingo
> **Arxiv** [2204.14198](https://arxiv.org/abs/2204.14198)
>
> **翻译** [2204.14198](https://hjfy.top/arxiv/2204.14198)
>
> **代码** [Github](https://github.com/mlfoundations/open_flamingo)
>
> **Demo** [Demo](https://huggingface.co/spaces/dhansmair/flamingo-mini-cap)

## Frozen

> [!NOTE] Frozen
> **Arxiv** [2106.13884](https://arxiv.org/abs/2106.13884)
>
> **翻译** [2106.13884](https://hjfy.top/arxiv/2106.13884)

> [!IMPORTANT] 待读论文
> 本文档包含多模态上下文学习相关的待读论文列表,持续更新中...
