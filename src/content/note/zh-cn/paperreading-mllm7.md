---
title: "PaperReading: MLLM_7 - Foundation Models"
timestamp: 2026-01-31 00:00:00+08:00
series: PaperReading
tags: [MLLM, Paper, Foundation]
description: 多模态基础模型相关论文阅读。
---

### Description

> [!NOTE] 普通论文
> 标准论文记录,蓝色

> [!TIP] 推荐阅读
> 特别推荐的经典论文,绿色

> [!IMPORTANT] 重要突破
> 里程碑式的重要论文,紫色

> [!WARNING] 需注意
> 有争议或需要特别注意的论文,橙色

<br>

## GPT-5

> [!IMPORTANT] GPT-5
> **发布** OpenAI
>
> **链接** [Introducing GPT-5](https://openai.com/index/introducing-gpt-5/)

## VideoLLaMA 3

> [!NOTE] VideoLLaMA 3
> **Arxiv** [2501.13106](https://arxiv.org/abs/2501.13106)
>
> **翻译** [2501.13106](https://hjfy.top/arxiv/2501.13106)
>
> **代码** [Github](https://github.com/DAMO-NLP-SG/VideoLLaMA3)
>
> **Demo** [Demo](https://huggingface.co/spaces/lixin4ever/VideoLLaMA3)

## Emu3

> [!NOTE] Emu3
> **Arxiv** [2409.18869](https://arxiv.org/abs/2409.18869)
>
> **翻译** [2409.18869](https://hjfy.top/arxiv/2409.18869)
>
> **代码** [Github](https://github.com/baaivision/Emu3)

## Llama 3.2

> [!IMPORTANT] Llama 3.2
> **发布** Meta
>
> **链接** [Llama 3.2 Blog](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
>
> **Demo** [Demo](https://huggingface.co/meta-llama/Llama-3.2-11B-Vision-Instruct)

## Pixtral-12B

> [!NOTE] Pixtral-12B
> **发布** Mistral
>
> **链接** [Pixtral-12B](https://mistral.ai/news/pixtral-12b/)

## xGen-MM (BLIP-3)

> [!NOTE] BLIP-3
> **Arxiv** [2408.08872](https://arxiv.org/abs/2408.08872)
>
> **翻译** [2408.08872](https://hjfy.top/arxiv/2408.08872)
>
> **代码** [Github](https://github.com/salesforce/LAVIS/tree/xgen-mm)

## Llama 3 Herd

> [!IMPORTANT] Llama 3
> **Arxiv** [2407.21783](https://arxiv.org/abs/2407.21783)
>
> **翻译** [2407.21783](https://hjfy.top/arxiv/2407.21783)

## Chameleon

> [!NOTE] Chameleon
> **Arxiv** [2405.09818](https://arxiv.org/abs/2405.09818)
>
> **翻译** [2405.09818](https://hjfy.top/arxiv/2405.09818)

## GPT-4o

> [!IMPORTANT] GPT-4o
> **发布** OpenAI
>
> **链接** [Hello GPT-4o](https://openai.com/index/hello-gpt-4o/)

## Claude 3

> [!IMPORTANT] Claude 3
> **发布** Anthropic
>
> **PDF** [Claude 3 Model Card](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)

## Gemini 1.5

> [!IMPORTANT] Gemini 1.5
> **发布** Google
>
> **PDF** [Gemini 1.5 Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf)

## Gemini

> [!IMPORTANT] Gemini
> **发布** Google
>
> **PDF** [Gemini 1 Report](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf)

## Fuyu-8B

> [!NOTE] Fuyu-8B
> **发布** Adept
>
> **链接** [Fuyu-8B Blog](https://www.adept.ai/blog/fuyu-8b)
>
> **模型** [Huggingface](https://huggingface.co/adept/fuyu-8b)
>
> **Demo** [Demo](https://huggingface.co/adept/fuyu-8b)

## UnIVAL

> [!NOTE] UnIVAL
> **Arxiv** [2307.16184](https://arxiv.org/abs/2307.16184)
>
> **翻译** [2307.16184](https://hjfy.top/arxiv/2307.16184)
>
> **代码** [Github](https://github.com/mshukor/UnIVAL)
>
> **Demo** [Demo](https://huggingface.co/spaces/mshukor/UnIVAL)

## PaLI-3

> [!NOTE] PaLI-3
> **Arxiv** [2310.09199](https://arxiv.org/abs/2310.09199)
>
> **翻译** [2310.09199](https://hjfy.top/arxiv/2310.09199)

## GPT-4V

> [!IMPORTANT] GPT-4V
> **发布** OpenAI
>
> **PDF** [GPT-4V System Card](https://cdn.openai.com/papers/GPTV_System_Card.pdf)

## LaVIT

> [!NOTE] LaVIT
> **Arxiv** [2309.04669](https://arxiv.org/abs/2309.04669)
>
> **翻译** [2309.04669](https://hjfy.top/arxiv/2309.04669)
>
> **代码** [Github](https://github.com/jy0205/LaVIT)

## Multimodal Foundation Models Survey

> [!TIP] Survey
> **Arxiv** [2309.10020](https://arxiv.org/abs/2309.10020)
>
> **翻译** [2309.10020](https://hjfy.top/arxiv/2309.10020)

## BLIText

> [!NOTE] BLIText
> **Arxiv** [2307.07063](https://arxiv.org/abs/2307.07063)
>
> **翻译** [2307.07063](https://hjfy.top/arxiv/2307.07063)
>
> **代码** [Github](https://github.com/yiren-jian/BLIText)

## Kosmos-2

> [!NOTE] Kosmos-2
> **Arxiv** [2306.14824](https://arxiv.org/abs/2306.14824)
>
> **翻译** [2306.14824](https://hjfy.top/arxiv/2306.14824)
>
> **代码** [Github](https://github.com/microsoft/unilm/tree/master/kosmos-2)
>
> **Demo** [Demo](https://aka.ms/kosmos-2-demo)

## VPGTrans

> [!NOTE] VPGTrans
> **Arxiv** [2305.01278](https://arxiv.org/abs/2305.01278)
>
> **翻译** [2305.01278](https://hjfy.top/arxiv/2305.01278)
>
> **代码** [Github](https://github.com/VPGTrans/VPGTrans)
>
> **Demo** [Demo](https://3fc7715dbc44234a7f.gradio.live/)

## GPT-4

> [!IMPORTANT] GPT-4
> **Arxiv** [2303.08774](https://arxiv.org/abs/2303.08774)
>
> **翻译** [2303.08774](https://hjfy.top/arxiv/2303.08774)

## PaLM-E

> [!NOTE] PaLM-E
> **Arxiv** [2303.03378](https://arxiv.org/abs/2303.03378)
>
> **翻译** [2303.03378](https://hjfy.top/arxiv/2303.03378)
>
> **Demo** [Demo](https://palm-e.github.io/#demo)

## Prismer

> [!NOTE] Prismer
> **Arxiv** [2303.02506](https://arxiv.org/abs/2303.02506)
>
> **翻译** [2303.02506](https://hjfy.top/arxiv/2303.02506)
>
> **代码** [Github](https://github.com/NVlabs/prismer)
>
> **Demo** [Demo](https://huggingface.co/spaces/lorenmt/prismer)

## Kosmos-1

> [!NOTE] Kosmos-1
> **Arxiv** [2302.14045](https://arxiv.org/abs/2302.14045)
>
> **翻译** [2302.14045](https://hjfy.top/arxiv/2302.14045)
>
> **代码** [Github](https://github.com/microsoft/unilm)

## BLIP-2

> [!IMPORTANT] BLIP-2
> **Arxiv** [2301.12597](https://arxiv.org/abs/2301.12597)
>
> **翻译** [2301.12597](https://hjfy.top/arxiv/2301.12597)
>
> **代码** [Github](https://github.com/salesforce/LAVIS/tree/main/projects/blip2)
>
> **Demo** [Demo](https://colab.research.google.com/github/salesforce/LAVIS/blob/main/examples/blip2_instructed_generation.ipynb)

## VIMA

> [!NOTE] VIMA
> **Arxiv** [2210.03094](https://arxiv.org/abs/2210.03094)
>
> **翻译** [2210.03094](https://hjfy.top/arxiv/2210.03094)
>
> **代码** [Github](https://github.com/vimalabs/VIMA)

## MineDojo

> [!NOTE] MineDojo
> **Arxiv** [2206.08853](https://arxiv.org/abs/2206.08853)
>
> **翻译** [2206.08853](https://hjfy.top/arxiv/2206.08853)
>
> **代码** [Github](https://github.com/MineDojo/MineDojo)

## DaVinci

> [!NOTE] DaVinci
> **Arxiv** [2206.07699](https://arxiv.org/abs/2206.07699)
>
> **翻译** [2206.07699](https://hjfy.top/arxiv/2206.07699)
>
> **代码** [Github](https://github.com/shizhediao/DaVinci)

## MetaLM

> [!NOTE] MetaLM
> **Arxiv** [2206.06336](https://arxiv.org/abs/2206.06336)
>
> **翻译** [2206.06336](https://hjfy.top/arxiv/2206.06336)
>
> **代码** [Github](https://github.com/microsoft/unilm)

> [!IMPORTANT] 待读论文
> 本文档包含多模态基础模型相关的待读论文列表,持续更新中...
