---
title: "PaperReading: MLLM_8 - Evaluation & RLHF"
timestamp: 2026-01-31 00:00:00+08:00
series: PaperReading
tags: [MLLM, Paper, Evaluation, RLHF]
description: 多模态评估与人类反馈强化学习相关论文阅读。
---

### Description

> [!NOTE] 普通论文
> 标准论文记录,蓝色

> [!TIP] 推荐阅读
> 特别推荐的经典论文,绿色

> [!IMPORTANT] 重要突破
> 里程碑式的重要论文,紫色

> [!WARNING] 需注意
> 有争议或需要特别注意的论文,橙色

<br>

## Evaluation Benchmarks

### Thinking in Space

> [!NOTE] Thinking in Space
> **Arxiv** [2412.14171](https://arxiv.org/abs/2412.14171)
>
> **翻译** [2412.14171](https://hjfy.top/arxiv/2412.14171)
>
> **代码** [Github](https://github.com/vision-x-nyu/thinking-in-space)

### MMGenBench

> [!NOTE] MMGenBench
> **Arxiv** [2411.14062](https://arxiv.org/abs/2411.14062)
>
> **翻译** [2411.14062](https://hjfy.top/arxiv/2411.14062)
>
> **代码** [Github](https://github.com/lerogo/MMGenBench)

### OmniBench

> [!NOTE] OmniBench
> **Arxiv** [2409.15272](https://arxiv.org/abs/2409.15272)
>
> **翻译** [2409.15272](https://hjfy.top/arxiv/2409.15272)
>
> **代码** [Github](https://github.com/multimodal-art-projection/OmniBench)

### MME-RealWorld

> [!IMPORTANT] MME-RealWorld
> **Arxiv** [2408.13257](https://arxiv.org/abs/2408.13257)
>
> **翻译** [2408.13257](https://hjfy.top/arxiv/2408.13257)
>
> **代码** [Github](https://github.com/yfzhang114/MME-RealWorld)

### UNK-VQA

> [!NOTE] UNK-VQA
> **Arxiv** [2310.10942](https://arxiv.org/abs/2310.10942)
>
> **翻译** [2310.10942](https://hjfy.top/arxiv/2310.10942)
>
> **代码** [Github](https://github.com/guoyang9/UNK-VQA)

### MMEvalPro

> [!NOTE] MMEvalPro
> **Arxiv** [2407.00468](https://arxiv.org/abs/2407.00468)
>
> **翻译** [2407.00468](https://hjfy.top/arxiv/2407.00468)
>
> **代码** [Github](https://github.com/chenllliang/MMEvalPro)

### Web2Code

> [!NOTE] Web2Code
> **Arxiv** [2406.20098](https://arxiv.org/abs/2406.20098)
>
> **翻译** [2406.20098](https://hjfy.top/arxiv/2406.20098)
>
> **代码** [Github](https://github.com/MBZUAI-LLM/web2code)

### CharXiv

> [!NOTE] CharXiv
> **Arxiv** [2406.18521](https://arxiv.org/abs/2406.18521)
>
> **翻译** [2406.18521](https://hjfy.top/arxiv/2406.18521)
>
> **代码** [Github](https://github.com/princeton-nlp/CharXiv)

### ChartMimic

> [!NOTE] ChartMimic
> **Arxiv** [2406.09961](https://arxiv.org/abs/2406.09961)
>
> **翻译** [2406.09961](https://hjfy.top/arxiv/2406.09961)
>
> **代码** [Github](https://github.com/ChartMimic/ChartMimic)

### Video-MME

> [!IMPORTANT] Video-MME
> **Arxiv** [2405.21075](https://arxiv.org/abs/2405.21075)
>
> **翻译** [2405.21075](https://hjfy.top/arxiv/2405.21075)
>
> **代码** [Github](https://github.com/BradyFU/Video-MME)

### MMCBench

> [!NOTE] MMCBench
> **Arxiv** [2401.11943](https://arxiv.org/abs/2401.11943)
>
> **翻译** [2401.11943](https://hjfy.top/arxiv/2401.11943)
>
> **代码** [Github](https://github.com/sail-sg/MMCBench)

### MMVP

> [!NOTE] MMVP
> **Arxiv** [2401.06209](https://arxiv.org/abs/2401.06209)
>
> **翻译** [2401.06209](https://hjfy.top/arxiv/2401.06209)
>
> **代码** [Github](https://github.com/tsb0601/MMVP)

### Gemini Evaluation

> [!NOTE] Gemini Eval
> **Arxiv** [2312.12436](https://arxiv.org/abs/2312.12436)
>
> **翻译** [2312.12436](https://hjfy.top/arxiv/2312.12436)
>
> **代码** [Github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)

### BenchLMM

> [!NOTE] BenchLMM
> **Arxiv** [2312.02896](https://arxiv.org/abs/2312.02896)
>
> **翻译** [2312.02896](https://hjfy.top/arxiv/2312.02896)
>
> **代码** [Github](https://github.com/AIFEG/BenchLMM)

### VLLM-Safety

> [!NOTE] Safety Benchmark
> **Arxiv** [2311.16101](https://arxiv.org/abs/2311.16101)
>
> **翻译** [2311.16101](https://hjfy.top/arxiv/2311.16101)
>
> **代码** [Github](https://github.com/UCSC-VLAA/vllm-safety-benchmark)

### Geographic Capabilities

> [!NOTE] GeoEval
> **Arxiv** [2311.14656](https://arxiv.org/abs/2311.14656)
>
> **翻译** [2311.14656](https://hjfy.top/arxiv/2311.14656)
>
> **代码** [Github](https://github.com/jonathan-roberts1/charting-new-territories)

### MLLM-Bench

> [!NOTE] MLLM-Bench
> **Arxiv** [2311.13951](https://arxiv.org/abs/2311.13951)
>
> **翻译** [2311.13951](https://hjfy.top/arxiv/2311.13951)
>
> **代码** [Github](https://github.com/FreedomIntelligence/MLLM-Bench)

### VLM-Eval

> [!NOTE] VLM-Eval
> **Arxiv** [2311.11865](https://arxiv.org/abs/2311.11865)
>
> **翻译** [2311.11865](https://hjfy.top/arxiv/2311.11865)

### Bingo (GPT-4V Hallucination)

> [!NOTE] Bingo
> **Arxiv** [2311.03287](https://arxiv.org/abs/2311.03287)
>
> **翻译** [2311.03287](https://hjfy.top/arxiv/2311.03287)
>
> **代码** [Github](https://github.com/gzcch/Bingo)

### GPT-4V on Autonomous Driving

> [!NOTE] GPT-4V AD
> **Arxiv** [2311.05332](https://arxiv.org/abs/2311.05332)
>
> **翻译** [2311.05332](https://hjfy.top/arxiv/2311.05332)
>
> **代码** [Github](https://github.com/PJLab-ADG/GPT4V-AD-Exploration)

### GPT-4V Medical Imaging

> [!NOTE] Medical Eval
> **Arxiv** [2310.20381](https://arxiv.org/abs/2310.20381)
>
> **翻译** [2310.20381](https://hjfy.top/arxiv/2310.20381)

### GPT-4V Early Evaluation

> [!NOTE] GPT-4V Eval
> **Arxiv** [2310.16534](https://arxiv.org/abs/2310.16534)
>
> **翻译** [2310.16534](https://hjfy.top/arxiv/2310.16534)
>
> **代码** [Github](https://github.com/albertwy/GPT-4V-Evaluation)

### GPT-4V OCR

> [!NOTE] OCR Eval
> **Arxiv** [2310.16809](https://arxiv.org/abs/2310.16809)
>
> **翻译** [2310.16809](https://hjfy.top/arxiv/2310.16809)
>
> **代码** [Github](https://github.com/SCUT-DLVCLab/GPT-4V_OCR)

### HallusionBench

> [!IMPORTANT] HallusionBench
> **Arxiv** [2310.14566](https://arxiv.org/abs/2310.14566)
>
> **翻译** [2310.14566](https://hjfy.top/arxiv/2310.14566)
>
> **代码** [Github](https://github.com/tianyi-lab/HallusionBench)

### MathVista

> [!IMPORTANT] MathVista
> **Arxiv** [2310.02255](https://arxiv.org/abs/2310.02255)
>
> **翻译** [2310.02255](https://hjfy.top/arxiv/2310.02255)
>
> **代码** [Github](https://github.com/lupantech/MathVista)

### TouchStone

> [!NOTE] TouchStone
> **Arxiv** [2308.16890](https://arxiv.org/abs/2308.16890)
>
> **翻译** [2308.16890](https://hjfy.top/arxiv/2308.16890)
>
> **代码** [Github](https://github.com/OFA-Sys/TouchStone)

### Sparkles

> [!NOTE] Sparkles
> **Arxiv** [2308.16463](https://arxiv.org/abs/2308.16463)
>
> **翻译** [2308.16463](https://hjfy.top/arxiv/2308.16463)
>
> **代码** [Github](https://github.com/HYPJUDY/Sparkles#sparkleseval)

### SciGraphQA

> [!NOTE] SciGraphQA
> **Arxiv** [2308.03349](https://arxiv.org/abs/2308.03349)
>
> **翻译** [2308.03349](https://hjfy.top/arxiv/2308.03349)
>
> **代码** [Github](https://github.com/findalexli/SciGraphQA)

### Tiny LVLM-eHub

> [!NOTE] Tiny eHub
> **Arxiv** [2308.03729](https://arxiv.org/abs/2308.03729)
>
> **翻译** [2308.03729](https://hjfy.top/arxiv/2308.03729)
>
> **代码** [Github](https://github.com/OpenGVLab/Multi-Modality-Arena)

### MM-Vet

> [!IMPORTANT] MM-Vet
> **Arxiv** [2308.02490](https://arxiv.org/abs/2308.02490)
>
> **翻译** [2308.02490](https://hjfy.top/arxiv/2308.02490)
>
> **代码** [Github](https://github.com/yuweihao/MM-Vet)

### SEED-Bench

> [!IMPORTANT] SEED-Bench
> **Arxiv** [2307.16125](https://arxiv.org/abs/2307.16125)
>
> **翻译** [2307.16125](https://hjfy.top/arxiv/2307.16125)
>
> **代码** [Github](https://github.com/AILab-CVC/SEED-Bench)

### MMBench

> [!IMPORTANT] MMBench
> **Arxiv** [2307.06281](https://arxiv.org/abs/2307.06281)
>
> **翻译** [2307.06281](https://hjfy.top/arxiv/2307.06281)
>
> **代码** [Github](https://github.com/open-compass/MMBench)

### MME

> [!IMPORTANT] MME
> **Arxiv** [2306.13394](https://arxiv.org/abs/2306.13394)
>
> **翻译** [2306.13394](https://hjfy.top/arxiv/2306.13394)
>
> **代码** [Github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Evaluation)

### LVLM-eHub

> [!NOTE] LVLM-eHub
> **Arxiv** [2306.09265](https://arxiv.org/abs/2306.09265)
>
> **翻译** [2306.09265](https://hjfy.top/arxiv/2306.09265)
>
> **代码** [Github](https://github.com/OpenGVLab/Multi-Modality-Arena)

### LAMM

> [!NOTE] LAMM
> **Arxiv** [2306.06687](https://arxiv.org/abs/2306.06687)
>
> **翻译** [2306.06687](https://hjfy.top/arxiv/2306.06687)
>
> **代码** [Github](https://github.com/OpenLAMM/LAMM#lamm-benchmark)

### M3Exam

> [!NOTE] M3Exam
> **Arxiv** [2306.05179](https://arxiv.org/abs/2306.05179)
>
> **翻译** [2306.05179](https://hjfy.top/arxiv/2306.05179)
>
> **代码** [Github](https://github.com/DAMO-NLP-SG/M3Exam)

### MultimodalOCR

> [!NOTE] OCR Mystery
> **Arxiv** [2305.07895](https://arxiv.org/abs/2305.07895)
>
> **翻译** [2305.07895](https://hjfy.top/arxiv/2305.07895)
>
> **代码** [Github](https://github.com/Yuliang-Liu/MultimodalOCR)

<br>

## Multimodal RLHF

### R1-Reward

> [!NOTE] R1-Reward
> **Arxiv** [2505.02835](https://arxiv.org/abs/2505.02835)
>
> **翻译** [2505.02835](https://hjfy.top/arxiv/2505.02835)
>
> **代码** [Github](https://github.com/yfzhang114/r1_reward)

### MLLM Alignment Survey

> [!TIP] Alignment Survey
> **Arxiv** [2503.14504](https://arxiv.org/abs/2503.14504)
>
> **翻译** [2503.14504](https://hjfy.top/arxiv/2503.14504)
>
> **代码** [Github](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/tree/Alignment)

### MM-RLHF

> [!NOTE] MM-RLHF
> **Arxiv** [2502.10391](https://arxiv.org/abs/2502.10391)
>
> **翻译** [2502.10391](https://hjfy.top/arxiv/2502.10391)
>
> **代码** [Github](https://github.com/Kwai-YuanQi/MM-RLHF)

### Video Captioning with Preference

> [!NOTE] Video Caption
> **Arxiv** [2410.06682](https://arxiv.org/abs/2410.06682)
>
> **翻译** [2410.06682](https://hjfy.top/arxiv/2410.06682)

### Silkie

> [!NOTE] Silkie
> **Arxiv** [2312.10665](https://arxiv.org/abs/2312.10665)
>
> **翻译** [2312.10665](https://hjfy.top/arxiv/2312.10665)
>
> **代码** [Github](https://github.com/vlf-silkie/VLFeedback)

### RoVRM

> [!NOTE] RoVRM
> **Arxiv** [2408.12109](https://arxiv.org/abs/2408.12109)
>
> **翻译** [2408.12109](https://hjfy.top/arxiv/2408.12109)
>
> **代码** [Github](https://github.com/wangclnlp/Vision-LLM-Alignment)

> [!IMPORTANT] 待读论文
> 本文档包含多模态评估与RLHF相关的待读论文列表,持续更新中...
